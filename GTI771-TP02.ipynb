{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Laboratoire 2\n",
    "# Discrimination linéaire et réseaux de neurones profonds\n",
    "## Classification et régression (Datasets FER et FG-NET)\n",
    "\n",
    "### GTI771 - Apprentissage machine avancé\n",
    "#### Département de génie logiciel et des technologies de l’information (LogTI)\n",
    "\n",
    "##### <font color=white> Version 1.0 - février 2020<br>Version 2.0 - février 2020 <br> Version 3.0 - mars 2020<br>Version 4.0 - juin 2020 (Richard Rail)<br>Version 4.1 - février 2021<br></font><br>Version 4.2 - février 2022<br>\n",
    "\n",
    "\n",
    "##### Prof. Alessandro L. Koerich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Étudiants             | Antoine Brassard Lahey - BRAA05089904 <br/>  Antoine Pelchat-Fortin - PELA04029703 <br/> Sébastien Charbonneau - CHAS01049805               |\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Session               | ÉTÉ 2022                                                |\n",
    "| Équipe                | 10                                                      |\n",
    "| Numéro du laboratoire | 2                                                       |\n",
    "| Professeur            | Hervé Lombaert                                          |\n",
    "| Chargé de laboratoire | Lucas Geffard                                           |\n",
    "| Date                  | 2022-07-12                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ce deuxième laboratoire porte sur l'utilisation de trois algorithmes d'apprentissage soit les algorithmes de régression, les réseaux neuronaux et les réseaux neuronaux profonds. Dans ce laboratoire, vous êtes amenés à utiliser de nouvelles approches à l’aide de ces algorithmes aﬁn de résoudre deux problèmes: prédiction de l'âge de personnes à partir de photos du visage (régression); problème de classiﬁcation des expressions faciales (FER) introduit dans le cadre du premier laboratoire de ce cours.\n",
    "\n",
    "Le problème de régression qui vous est présenté est le problème [Facial Aging Estimation (FAE)](https://yanweifu.github.io/FG_NET_data/index.html), dont le but est de prédire l'âge des personnes à partir du visage. En vous basant sur les concepts vus en classe et l'expérience acquise dans le laboratoire 1, vous êtes invité à reprendre les primitives développées lors du laboratoire 1 ou d'autres primitives que vous jugez pertinentes à extraire sur ces types d’images et effectuer l’extraction de celles-ci sur l’ensemble de données fournies avec cet énoncé. \n",
    "\n",
    "##### Description de l'ensemble de données:\n",
    "* 1002 images faciales de 82 sujets multiraciaux âgés de 0 à 69 ans;\n",
    "* Déséquilibré: 50% des sujets ont entre 0 et 13 ans;\n",
    "* Images couleur et niveaux de gris avec une dimension moyenne de 384x487 pixels, et la résolution varie de 200 dpi à 1200 dpi;\n",
    "* Grande variation d'éclairage, de pose, d'expression faciale, de flou et d'occlusions (par exemple, moustache, barbe, lunettes, etc.).\n",
    "\n",
    "Voici, en exemple, des images de visages se retrouvant dans l’ensemble de données FG-NET:\n",
    "\n",
    "![Exemples de FER](https://www.mdpi.com/sensors/sensors-16-00994/article_deploy/html/images/sensors-16-00994-g001.png)\n",
    "\n",
    "Veuillez noter que les images qui vous sont fournies ne sont pas nécessairement similaires aux images de FER. Plusieurs images comportent du bruit, des artéfacts ou des éléments non pertinents. Le défi de ce laboratoire repose sur cette difficulté qui est chose courante dans des problèmes d’apprentissage machine moderne.\n",
    "\n",
    "Tout comme le premier travail pratique, vous réaliserez ce deuxième laboratoire avec la technologie Python3 conjointement avec la librairie d’apprentissage machine scikit-learn et TensorFlow et Keras pour la partie réseaux de neurones. Vous êtes invité à reprendre le code développé lors du laboratoire 1 afin de continuer son développement.\n",
    "\n",
    "<font color=black> L’évaluation de ce laboratoire sera basée sur la qualité des modèles entraînés, la comparaison des performances réalisées par les différents modèles, les réponses aux questions dans cette notebook ainsi que l'organisation de votre code source (SVP, n'oubliez pas des commentaires dans le code!).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Partie 1: Régression\n",
    "* Régression lineaire\n",
    "* Régression Ridge\n",
    "* Régression Lasso et Elastic-Net\n",
    "* Descente du gradiente stochastique (SGD)<br>\n",
    "<br>\n",
    "* #### Partie 2: Classification\n",
    "* Régression logistique\n",
    "* Réseaux de neurones MLP <br>\n",
    "<br>\n",
    "* #### Partie 3: Classification et régression\n",
    "* Réseaux convolutionel entraîné \"from scratch\"\n",
    "* Réseaux convolutionel + modèles pre-entraînes (transfer learning)\n",
    "* Réseaux convolutionel adapté à la régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Partie 0: Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (0a) Import de bibliotèques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### À faire:\n",
    "1. Ajouter toutes les bibliothèques que vous avez utilisées pour compléter ce notebook dans une cellule avec une petite description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy - Used to manipulate matrices\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib - 2D plotting library\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# Library to extract features from images. Used for LBP\n",
    "import skimage\n",
    "from skimage import feature\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "# SKLearn - Implementations of different machine learning models, used for tuning as well\n",
    "import absl\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import ResNet50, MobileNetV2, VGG19, InceptionResNetV2, EfficientNetV2L\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, Dropout, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# OpenCV - Includes functions for computervision. Used for image preprocessing and SIFT implementation.\n",
    "import cv2\n",
    "\n",
    "# Used to get float maxvalue\n",
    "import sys\n",
    "\n",
    "# Used for file system operations\n",
    "import os\n",
    "\n",
    "# Used to write csv datasets\n",
    "import csv\n",
    "\n",
    "# Used to manipulate tabular data (dataframes)\n",
    "import pandas\n",
    "\n",
    "# Used to save models\n",
    "import pickle as pkl\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import tensorflow as tf\n",
    "labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (0b) Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### À faire:\n",
    "Avez-vous créé des fonctions? Si oui, vous devez les mettre ici, avec une description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basé sur TM_SQDIFF dans opencv (décrit ici: https://docs.opencv.org/3.4/de/da9/tutorial_template_matching.html)\n",
    "def img_sqdiff(img1, img2):\n",
    "  return np.sum(np.square(img1 - img2))\n",
    "\n",
    "def classify_template_match(templates, img):\n",
    "  min_diff = sys.maxsize\n",
    "  min_idx = -1\n",
    "\n",
    "  for idx, template in enumerate(templates):\n",
    "    diff = img_sqdiff(template, img)\n",
    "    if diff < min_diff:\n",
    "      min_diff = diff\n",
    "      min_idx = idx\n",
    "\n",
    "  return min_idx\n",
    "\n",
    "def classify_template_match_dataset(templates, X):\n",
    "  return [classify_template_match(templates, img) for img in X]\n",
    "\n",
    "def extract_lbp(img, nb_points, radius, n_bins):\n",
    "  lbp = feature.local_binary_pattern(img, nb_points, radius, method='uniform')\n",
    "  (histogram, _) = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "  return histogram\n",
    "\n",
    "def extract_lbp_dataset(dataset, nb_points, radius, n_bins):\n",
    "  return np.array([extract_lbp(img[0], nb_points, radius, n_bins) for img in dataset])\n",
    "\n",
    "def make_csv_dataset(X, y, usage):\n",
    "  dataset = []\n",
    "  for (data, label) in zip(X, y):\n",
    "    data_str = \" \".join([str(x) for x in data.ravel()])\n",
    "    dataset.append([label, data_str, usage])\n",
    "  return dataset\n",
    "\n",
    "def write_FER_csv(output_path, data, data_header):\n",
    "  with open(output_path, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['emotion', data_header, 'USAGE'])\n",
    "    writer.writerows(data)\n",
    "\n",
    "def read_FER_csv(input_path, feature_length):\n",
    "  data = np.loadtxt(input_path, delimiter=',', dtype=str )\n",
    "  (Xtrain, ytrain) = split_FER_csv(data, 1, 28710, feature_length)\n",
    "  (Xtest, ytest) = split_FER_csv(data, 28710, 32299, feature_length)\n",
    "  (Xval, yval) = split_FER_csv(data, 32299, 35888, feature_length)\n",
    "  return Xtrain, ytrain, Xtest, ytest, Xval, yval\n",
    "\n",
    "def split_FER_csv(data, start_index, end_index, feature_length):\n",
    "  X = np.ones((end_index - start_index, feature_length), float)\n",
    "  \n",
    "  for i in range(start_index, end_index):\n",
    "    X[i-start_index] = data[i,1].split(\" \")\n",
    "\n",
    "  y = data[start_index:end_index, 0].astype(int)\n",
    "\n",
    "  return (X, y)\n",
    "\n",
    "def eval_model(model, x_train, y_train, x_val, y_val, x_test, y_test, titre):\n",
    "  # Classification\n",
    "  ypred_train = model.predict(x_train)\n",
    "  print(type(ypred_train[0]))\n",
    "  if not(isinstance(ypred_train[0], np.int32) or isinstance(ypred_train[0], np.int64)):\n",
    "    ypred_train = np.argmax(ypred_train, axis=1)\n",
    "        \n",
    "  training_accuracy = sklearn.metrics.accuracy_score(y_train, ypred_train, normalize=True, sample_weight=None)\n",
    "  print(\"Training accuracy: \")\n",
    "  print(str(training_accuracy * 100) + '%')\n",
    "  print(\"Training error: \")\n",
    "  print(str((1 - training_accuracy) * 100) + '%')\n",
    "\n",
    "  ypred_val = model.predict(x_val)\n",
    "  if not(isinstance(ypred_val[0], np.int32) or isinstance(ypred_val[0], np.int64)):\n",
    "    ypred_val = np.argmax(ypred_val, axis=1)\n",
    "    \n",
    "  validation_accuracy = sklearn.metrics.accuracy_score(y_val, ypred_val, normalize=True, sample_weight=None)\n",
    "  print(\"Validation accuracy: \")\n",
    "  print(str(validation_accuracy * 100) + '%')\n",
    "  print(\"Validation error: \")\n",
    "  print(str((1 - validation_accuracy) * 100) + '%')\n",
    "\n",
    "\n",
    "  ypred_test = model.predict(x_test)\n",
    "  if not(isinstance(ypred_test[0], np.int32) or isinstance(ypred_test[0], np.int64)):\n",
    "    ypred_test = np.argmax(ypred_test, axis=1)\n",
    "    \n",
    "  test_accuracy = sklearn.metrics.accuracy_score(y_test, ypred_test, normalize=True, sample_weight=None)\n",
    "  print(\"Test accuracy: \")\n",
    "  print(str(test_accuracy * 100) + '%')\n",
    "  print(\"Test error: \")\n",
    "  print(str((1 - test_accuracy) * 100) + '%')\n",
    "\n",
    "\n",
    "  train_precision = sklearn.metrics.precision_score(y_train, ypred_train, average='micro')\n",
    "  validation_precision = sklearn.metrics.precision_score(y_val, ypred_val, average='micro')\n",
    "  test_precision = sklearn.metrics.precision_score(y_test, ypred_test, average='micro')\n",
    "  avg_precision = (train_precision + validation_precision + test_precision) / 3\n",
    "  print(\"Average precision: \" + str(avg_precision * 100) + '%')\n",
    "\n",
    "\n",
    "  # Confusion matrix\n",
    "  matrice_confusion = sklearn.metrics.confusion_matrix(y_true=y_test, y_pred=ypred_test, labels=[i for i in range(0, len(labels))])\n",
    "  disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=matrice_confusion, display_labels=labels)\n",
    "  disp.plot()\n",
    "  plt.title(f'Matrice de confusion - {titre}')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def extract_SIFT(images, k):\n",
    "  (sift, descriptors) = extract_SIFT_features(images)\n",
    "  kmeans = clustering(descriptors, k)\n",
    "  sift_histograms = create_histograms(sift, kmeans, images, k)\n",
    "  return sift_histograms\n",
    "  \n",
    "\n",
    "def extract_SIFT_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    descriptor_list = []\n",
    "    \n",
    "    for image in images:\n",
    "        _, descriptors = sift.detectAndCompute(image, None)\n",
    "        \n",
    "        if descriptors is not None:\n",
    "            for d in descriptors:\n",
    "                descriptor_list.append(d)\n",
    "                \n",
    "    descriptor_list = np.asarray(descriptor_list)\n",
    "    \n",
    "    return (sift, descriptor_list.astype('double'))\n",
    "\n",
    "def clustering(descriptors, k):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k, random_state=0).fit(descriptors)\n",
    "    return kmeans\n",
    "\n",
    "def create_histograms(sift, kmeans, images, k):\n",
    "    histogram_list = []\n",
    "    kmeans = kmeans\n",
    "    \n",
    "    for img in images:\n",
    "        keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "        \n",
    "        histo = np.zeros(k)\n",
    "        n_keypoints = np.size(keypoints)\n",
    "        \n",
    "        if descriptors is not None:\n",
    "            for d in descriptors:\n",
    "                idx = kmeans.predict([d])\n",
    "                histo[idx] += 1/n_keypoints\n",
    "            \n",
    "        histogram_list.append(histo)\n",
    "\n",
    "    return histogram_list\n",
    "\n",
    "def create_dim_reduction_models(Xtrain, ytrain, n_components, k_features):\n",
    "    pca = sklearn.decomposition.PCA(n_components=n_components)\n",
    "    Xtrain = pca.fit_transform(Xtrain)\n",
    "\n",
    "    k_best = SelectKBest(f_classif, k=k_features)\n",
    "    k_best.fit_transform(Xtrain, ytrain)\n",
    "\n",
    "    return (pca, k_best)\n",
    "\n",
    "def reduce_dimensionality(pca, k_best, Xtrain, Xtest, Xval):\n",
    "    Xtrain = k_best.transform(pca.transform(Xtrain))\n",
    "    Xtest = k_best.transform(pca.transform(Xtest))\n",
    "    Xval = k_best.transform(pca.transform(Xval))\n",
    "    return (Xtrain, Xtest, Xval)\n",
    "\n",
    "def plot_dim_reduction(pca, n_components, Xtrain, ytrain):\n",
    "    Xtrain = SelectKBest(f_classif, k=2).fit_transform(Xtrain, ytrain)\n",
    "    pixel_pca1 = Xtrain[:,0]\n",
    "    pixel_pca2 = Xtrain[:,1]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for label in np.unique(ytrain):\n",
    "        ix = np.where( ytrain == label)\n",
    "        ax.scatter(pixel_pca1[ix], pixel_pca2[ix], label = labels[label])\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cum_explained_variance = np.cumsum(explained_variance)\n",
    "    idx = np.arange(n_components) + 1\n",
    "    features_explained_variance = pandas.DataFrame([explained_variance, cum_explained_variance], \n",
    "                                        index=['explained variance', 'cumulative'], \n",
    "                                        columns=idx).T\n",
    "    mean_explained_variance = features_explained_variance.iloc[:,0].mean() # calculate mean explained variance\n",
    "        \n",
    "    print('PCA Overview')\n",
    "    print(features_explained_variance.head(100))\n",
    "\n",
    "def eval_jaffe(model, x_test, y_test, titre):\n",
    "  ypred_test = model.predict(x_test)\n",
    "  print(\"Test score: \")\n",
    "  print(sklearn.metrics.accuracy_score(y_test, ypred_test, normalize=True, sample_weight=None))\n",
    "\n",
    "  # Confusion matrix\n",
    "  matrice_confusion = sklearn.metrics.confusion_matrix(y_true=y_test, y_pred=ypred_test, labels=[i for i in range(0, len(labels))])\n",
    "  disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=matrice_confusion, display_labels=labels)\n",
    "  disp.plot()\n",
    "  plt.title(f'Matrice de confusion - {titre}')\n",
    "  plt.show()\n",
    "\n",
    "def save_model(model, pkl_name):\n",
    "    # Save model\n",
    "    pickle = open(f'Models/{pkl_name}.pkl', 'wb') \n",
    "    pkl.dump(model, pickle)\n",
    "    pickle.close()\n",
    "    \n",
    "def convert_to_rgb(Xtrain, Xval, Xtest, width, length):\n",
    "    Xtrain_rgb = np.zeros((Xtrain.shape[0], width, length, 3))\n",
    "    Xval_rgb = np.zeros((Xval.shape[0], width, length, 3))\n",
    "    Xtest_rgb = np.zeros((Xtest.shape[0], width, length, 3))\n",
    "    \n",
    "    for i, image in enumerate(Xtrain):\n",
    "        to_rgb = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "        Xtrain_rgb[i] = to_rgb\n",
    "        \n",
    "    for i, image in enumerate(Xval):\n",
    "        to_rgb = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "        Xval_rgb[i] = to_rgb\n",
    "        \n",
    "    for i, image in enumerate(Xtest):\n",
    "        to_rgb = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "        Xtest_rgb[i] = to_rgb\n",
    "        \n",
    "    return Xtrain_rgb, Xval_rgb, Xtest_rgb\n",
    "\n",
    "def convert_grayscale_to_3_channels(Xtrain, Xval, Xtest, width, length):\n",
    "    Xtrain_stacked_grayscale = np.zeros((Xtrain.shape[0], width, length, 3))\n",
    "    Xval_stacked_grayscale = np.zeros((Xval.shape[0], width, length, 3))\n",
    "    Xtest_stacked_grayscale = np.zeros((Xtest.shape[0], width, length, 3))\n",
    "    \n",
    "    for i, image in enumerate(Xtrain):\n",
    "        stacked_img = np.concatenate((image,)*3, axis=-1)\n",
    "        Xtrain_stacked_grayscale[i] = stacked_img\n",
    "    \n",
    "    for i, image in enumerate(Xval):\n",
    "        stacked_img = np.concatenate((image,)*3, axis=-1)\n",
    "        Xval_stacked_grayscale[i] = stacked_img\n",
    "        \n",
    "    for i, image in enumerate(Xtest):\n",
    "        stacked_img = np.concatenate((image,)*3, axis=-1)\n",
    "        Xtest_stacked_grayscale[i] = stacked_img\n",
    "        \n",
    "    return Xtrain_stacked_grayscale, Xval_stacked_grayscale, Xtest_stacked_grayscale\n",
    "\n",
    "def transfer_train(pre_trained_model, Xtrain, ytrain):\n",
    "  for layer in pre_trained_model.layers:\n",
    "      layer.trainable = False\n",
    "\n",
    "  transfer_trained_model = Sequential()\n",
    "  transfer_trained_model.add(pre_trained_model)\n",
    "\n",
    "  # On ajoute les couches pour la classification\n",
    "  transfer_trained_model.add(Flatten())\n",
    "  transfer_trained_model.add(Dense(100, activation='relu'))\n",
    "  transfer_trained_model.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "  # Training avec images greyscale 3 channels (stacked)\n",
    "  transfer_trained_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  transfer_trained_model.fit(Xtrain, ytrain, epochs=30, batch_size=128, verbose=1, validation_split=0.2)\n",
    "  return transfer_trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1: Explorez les algorithmes de régression\n",
    "## FG-NET dataset (Facial Aging Estimation)\n",
    "\n",
    "Dans cette partie vous devez explorer les <b> algorithmes de régression linéaire </b> disponibles dans Scikit-learn, comme régression least square, régression Ridge, régression Lasso et Elastic-Net, descente du gradient stochastique (SGD), etc.\n",
    "\n",
    "Vous devez comparer la performance de ces algorithmes pour l'ensemble de données FG-NET sur:\n",
    "\n",
    "1. Le vecteur de pixels (images vectorisées)\n",
    "2. Vecteur de primitives (reprendre l'algorithme d'extraction de primitives que vous avez utilisées dans le Laboratoire 1, p.ex. LBP). Vous pouvez reprendre les primitives \"réduits\" que vous avez utilisées dans le Laboratoire 1 (p.ex. vecteur LBP après PCA), si vous pensez qu’ils sont plus performants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a: Charger le fichier de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_fgnet = np.loadtxt('Datasets/fgnet_256x256.csv', delimiter=',', dtype=int )\n",
    "y_fgnet = np.loadtxt('Datasets/fgnet_labels.csv', delimiter=',', dtype=int )\n",
    "\n",
    "X_fgnet = X_fgnet.reshape(X_fgnet.shape[0], 256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: Visualisation des visages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez visualiser les images en utilisant `plt.imshow`.\n",
    "\n",
    "Il y a différents types de prétraitement que nous pouvons appliquer à des images dans les ensembles de données pour réduire la variabilité, réduire des bruits, etc.\n",
    "\n",
    "Voici deux sources pour vous aidez à décider:\n",
    "- http://eprints.qut.edu.au/92300/1/manuscript_Jhony.pdf\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7475805\n",
    "\n",
    "### À faire:\n",
    "1. Pensez-vous qu’est nécessaire un prétraitement des images? Si oui, vous pouvez choisir différents algorithmes de prétraitement dans [scikit-image](https://scikit-image.org/docs/stable/api/api.html). Il y a aussi autres types de prétraitement plus généraux dans [scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n",
    "2. Expliquer et justifier les prétraitements choisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "X_fgnet_pretreated = []\n",
    "\n",
    "for image in X_fgnet:\n",
    "    image = image / np.max(image)\n",
    "    image = skimage.restoration.denoise_tv_bregman(image)\n",
    "    image = cv2.resize(image, (48, 48))\n",
    "    X_fgnet_pretreated.append(image)\n",
    "\n",
    "X_fgnet = np.array(X_fgnet_pretreated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats et réponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre explication/justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c: Statistiques sur les sujets et étiquettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### À faire:\n",
    "1. Calculer quelques statistiques (# images par sujet, distribution des âges, etc.) que vous jugez importantes sur les données\n",
    "2. Faire une analyse des résultats et présenter vos conclusions basées sur ces statistiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "\n",
    "# Code exemple:\n",
    "# Histogramme des étiquettes\n",
    "#hist, _ = np.histogram(ytrain, density=False, bins=7, range=(0, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats et réponses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vos résultats ici:\n",
    "\n",
    "# Code exemple:\n",
    "# Code exemple\n",
    "# Plot du histogramme\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d: Créer et évaluer des modèles de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### À faire:\n",
    "1. Choisir au moins trois (3) algorithmes de régression linéaire disponibles dans Scikit-learn (p.ex. régression least square, régression Ridge, régression Lasso, régression Elastic-Net, descente du gradient stochastique (SGD), etc.)\n",
    "2. Entraîner et optimiser les paramètres des modèles si nécessaire. Utiliser le protocole <font color=blue> \"Leave One Subject Out Cross-Validation\" </font> (LOSO).\n",
    "3. Faire une analyse des résultats et présenter vos conclusions sur les modèles de régression.\n",
    "\n",
    "| Algorithme            | Paramètres    |  MSE  |  MAE  |\n",
    "|-----------------------|---------------|-------|-------|\n",
    "| Regr lineaire         | XXX.XX        |XXX.XX |XXX.XX |\n",
    "| Regr Ridge            | alpha = 0.1   |123.34 | 10.45 |\n",
    "| Regr Lasso            | XXX.XX        |XXX.XX |XXX.XX |\n",
    "| Regr ElasticNet       | XXX.XX        |XXX.XX |XXX.XX |\n",
    "| ...                   | XXX.XX        |XXX.XX |XXX.XX |\n",
    "| ...                   | XXX.XX        |XXX.XX |XXX.XX |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats et réponses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vos résultats ici:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2: Explorez les algorithmes de classification\n",
    "## FER dataset ( Facial Expression Recognition )\n",
    "\n",
    "Vous devez reprendre l'ensemble FER et les primitives que vous avez choisis dans le Laboratoire 1.\n",
    "\n",
    "Dans cette partie vous devez explorer les algorithmes de classification <b> régression logistique et réseaux de neurones multicouches (MLP) </b>\n",
    "\n",
    "Vous devez comparer la performance de ces deux algorithmes pour l'ensemble FER sur:\n",
    "1. Le vecteur de pixels (images vectorisées)\n",
    "2. Vecteur de primitives (reprendre les primitives ou primitives sélectionnées/transformées du laboratoire 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a: Charger le fichier de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture features pixel, SIFT et LBP\n",
    "(Xtrain, ytrain, Xtest, ytest, Xval, yval) = read_FER_csv('Datasets/fer2013.csv', 2304)\n",
    "(Xtrain_lbp, ytrain_lbp, Xtest_lbp, ytest_lbp, Xval_lbp, yval_lbp) = read_FER_csv('Datasets/lbp_fer2013.csv', 18)\n",
    "(Xtrain_sift, ytrain_sift, Xtest_sift, ytest_sift, Xval_sift, yval_sift) = read_FER_csv('Datasets/sift_fer2013.csv', 10)\n",
    "\n",
    "Xtrain_flatten = Xtrain.reshape( Xtrain.shape[0], 2304 ).astype('uint8')\n",
    "Xtest_flatten  = Xtest.reshape( Xtest.shape[0], 2304 ).astype('uint8')\n",
    "Xval_flatten   = Xval.reshape( Xval.shape[0], 2304 ).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b: Créer et évaluer des modèles de classification (Régression logistique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### À faire:\n",
    "\n",
    "1. Utiliser l'algorithme régression logistique disponible dans [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), pour classifier le vecteur de pixels et le vecteur de primitives du laboratoire 1. Vous pouvez regarder aussi [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) et [LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV)\n",
    "2. Entraîner et optimiser les paramètres des modèles.\n",
    "3. Faire une analyse des résultats et présenter vos conclusions sur le modèle logistique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty':['l1', 'l2']\n",
    "}\n",
    "\n",
    "lr_classifier = LogisticRegression(solver=\"saga\", max_iter=10000)\n",
    "grid = GridSearchCV(lr_classifier, grid_params, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"SIFT\"\n",
    "# Training\n",
    "sift_grid_search = grid.fit(Xtrain_sift, ytrain)\n",
    "sift_lr_classifier = sift_grid_search.best_estimator_\n",
    "\n",
    "print(sift_grid_search.best_params_)\n",
    "\n",
    "# Save model\n",
    "save_model(sift_lr_classifier, 'sift_lr_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"pixel\"\n",
    "# Training\n",
    "pixel_grid_search = grid.fit(Xtrain_flatten, ytrain)\n",
    "pixel_lr_classifier = pixel_grid_search.best_estimator_\n",
    "\n",
    "print(pixel_grid_search.best_params_)\n",
    "\n",
    "# Save model\n",
    "save_model(pixel_lr_classifier, 'pixel_lr_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lbp\"\n",
    "# Training\n",
    "lbp_grid_search = grid.fit(Xtrain_lbp, ytrain)\n",
    "lbp_lr_classifier = lbp_grid_search.best_estimator_\n",
    "\n",
    "print(lbp_grid_search.best_params_)\n",
    "\n",
    "# Save model\n",
    "save_model(lbp_lr_classifier, 'lbp_lr_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(sift_lr_classifier, Xtrain_sift, ytrain_sift, Xtest_sift, ytest_sift, Xval_sift, yval_sift, 'SIFT logistic regression')\n",
    "# eval_model(pixel_lr_classifier, Xtrain_flatten, ytrain, Xtest_flatten, ytest, Xval_flatten, yval, 'pixel logistic regression')\n",
    "eval_model(lbp_lr_classifier, Xtrain_lbp, ytrain, Xtest_lbp, ytest, Xval_lbp, yval, 'LBP logistic regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Résultats et réponses:\n",
    "\n",
    "Vos résultats ici:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Algorithme                    | Paramètres    | Precision | %Erreur App | %Erreur Val | %Erreur Tst | \n",
    "|-------------------------------|---------------|-----------|-------------|-------------|-------------|\n",
    "| Regression logistique - SIFT  | C=10:L2       |   23.79%  |   74.47%    |   76.48%    |   77.68%    |\n",
    "| Regression logistique - Pixel |               |   xxx.xx  |   xxx.xx    |   XXX.XX    |   XXX.XX    |\n",
    "| Regression logistique - LBP   | C=10:l2       |   27.14%  |   72.65%    |   72.95%    |   72.97%    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c: Créer et évaluer des modèles de classification (Réseaux perceptron multi-couche)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### À faire:\n",
    "\n",
    "1. Utiliser [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones multicouche pour classifier les vecteurs de primitives du laboratoire 1. \n",
    "2. Choisir l’architecture appropriée pour chaque vecteur de primitives (nombre et dimension des couches). \n",
    "2. Entraîner et optimiser les paramètres des réseaux.\n",
    "4. Faire une analyse des résultats et présenter vos conclusions sur les réseaux de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one hot encoder\n",
    "ytrain_ohe = to_categorical(ytrain, len(labels))\n",
    "yval_ohe = to_categorical(yval, len(labels))\n",
    "ytest_ohe = to_categorical(ytest, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"SIFT\"\n",
    "sift_input_shape = Xtrain_sift[0].shape\n",
    "\n",
    "# Create the model\n",
    "sift_mlp_classifier = Sequential()\n",
    "sift_mlp_classifier.add(Dense(16, input_shape=sift_input_shape, activation='relu'))\n",
    "sift_mlp_classifier.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "# Training\n",
    "sift_mlp_classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "sift_mlp_classifier.fit(Xtrain_sift, ytrain_ohe, epochs=30, batch_size=128, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"pixel\"\n",
    "flatten_input_shape = Xtrain_flatten[0].shape\n",
    "\n",
    "# Create the model\n",
    "pixel_mlp_classifier = Sequential()\n",
    "pixel_mlp_classifier.add(Dense(512, input_shape=flatten_input_shape, activation='relu'))\n",
    "pixel_mlp_classifier.add(Dense(256, activation='relu'))\n",
    "pixel_mlp_classifier.add(Dense(128, activation='relu'))\n",
    "pixel_mlp_classifier.add(Dense(64, activation='relu'))\n",
    "pixel_mlp_classifier.add(Dense(32, activation='relu'))\n",
    "pixel_mlp_classifier.add(Dense(16, activation='relu'))\n",
    "pixel_mlp_classifier.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "# Training\n",
    "pixel_mlp_classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "pixel_mlp_classifier.fit(Xtrain_flatten, ytrain_ohe, epochs=30, batch_size=128, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lbp\"\n",
    "input_shape = Xtrain_lbp[0].shape\n",
    "\n",
    "# Create the model\n",
    "lbp_mlp_classifier = Sequential()\n",
    "lbp_mlp_classifier.add(Dense(64, input_shape=input_shape, activation='relu'))\n",
    "lbp_mlp_classifier.add(Dense(32, activation='relu'))\n",
    "lbp_mlp_classifier.add(Dense(16, activation='relu'))\n",
    "lbp_mlp_classifier.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "# Training\n",
    "lbp_mlp_classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lbp_mlp_classifier.fit(Xtrain_lbp, ytrain_ohe, epochs=30, batch_size=128, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(sift_mlp_classifier, Xtrain_sift, ytrain, Xtest_sift, ytest, Xval_sift, yval, 'SIFT mlp')\n",
    "eval_model(pixel_mlp_classifier, Xtrain_flatten, ytrain, Xtest_flatten, ytest, Xval_flatten, yval, 'pixel mlp')\n",
    "eval_model(lbp_mlp_classifier, Xtrain_lbp, ytrain, Xtest_lbp, ytest, Xval_lbp, yval, 'LBP mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats et réponses:\n",
    "Vos résultats ici\n",
    "\n",
    "| Algorithme       | Paramètres             | Precision | %Erreur App | %Erreur Val | %Erreur Tst | \n",
    "|------------------|------------------------|-----------|-------------|-------------|-------------|\n",
    "| MLP SIFT         | 16:7                   |   24.45%  |   74.54%    |   75.26%    |   76.76%    |\n",
    "| MLP Pixel        | 512:256:128:64:32:16:7 |   24.87%  |   74.85%    |   75.03%    |   75.51%    |\n",
    "| MLP LBP          | 64:32:16:7             |   26.77%  |   73.58%    |   72.58%    |   73.53%    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3: Explorez l'apprentissage de la représentation et les réseaux neuronaux profonds\n",
    "## (FER dataset et FG-NET dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### À faire :\n",
    "1. Utiliser [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones convolutif pour apprendre une représentation directement des images de visage aussi que les discriminantes. \n",
    "2. Choisir l’architecture appropriée : nombre de couches convolutifs (CL), dimension des filtres, “stride”, nombre de couches entièrement connectées (FC) et la dimension des couches). \n",
    "3. Entraîner et optimiser les paramètres du réseau.\n",
    "4. Évaluer la pertinence d’utiliser \"data augmentation\" pour améliorer la généralisation.\n",
    "5. Récupérer une des architectures CNN pré-entraînes disponibles dans Keras pour faire une “transfert de connaissance (transfer learning). Faire un \"fine-tuning\" du modèle choisi sur FER.    \n",
    "7. Choisir le modèle qu’a donné de meilleurs résultats sur FER et adapter ce modèle pour faire la régression sur FG-NET.     \n",
    "8. Faire une analyse des résultats et présenter vos conclusions sur les réseaux de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a: Code CNN (FER)\n",
    "    \n",
    "##### À faire:\n",
    "1. Utiliser [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones convolutif pour apprendre une représentation directement des images de visage aussi que les discriminantes. \n",
    "2. Choisir l’architecture appropriée: nombre de couches convolutifs (CL), dimension des filtres, \"stride”, nombre de couches entièrement connectées (FC) et la dimension des couches). \n",
    "3. Entraîner et optimiser les paramètres du réseau.\n",
    "4. Évaluer la pertinence d’utiliser \"data augmentation\" pour améliorer la généralisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture features pixel, SIFT et LBP\n",
    "(Xtrain, ytrain, Xtest, ytest, Xval, yval) = read_FER_csv('Datasets/fer2013.csv', 2304)\n",
    "\n",
    "Xtrain = Xtrain.reshape( Xtrain.shape[0], 48, 48, 1 ).astype('uint8')\n",
    "Xtest  = Xtest.reshape( Xtest.shape[0], 48, 48, 1 ).astype('uint8')\n",
    "Xval   = Xval.reshape( Xval.shape[0], 48, 48, 1 ).astype('uint8')\n",
    "\n",
    "ytrain_ohe = to_categorical(ytrain, len(labels))\n",
    "yval_ohe = to_categorical(yval, len(labels))\n",
    "ytest_ohe = to_categorical(ytest, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architecture adaptée à partir de LE: https://towardsdatascience.com/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342\n",
    "#\"pixel\"\n",
    "# Create the model\n",
    "pixel_cnn = Sequential()\n",
    "\n",
    "pixel_cnn.add(Conv2D(16, (5, 5), padding='same', input_shape=Xtrain[0].shape, activation='relu'))\n",
    "pixel_cnn.add(AveragePooling2D((2, 2), strides=2))\n",
    "\n",
    "pixel_cnn.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "pixel_cnn.add(AveragePooling2D((2, 2), strides=2))\n",
    "\n",
    "pixel_cnn.add(Flatten()),\n",
    "pixel_cnn.add(Dense(120, activation='relu'))\n",
    "pixel_cnn.add(Dropout(0.3))\n",
    "pixel_cnn.add(Dense(84, activation='relu'))\n",
    "pixel_cnn.add(Dropout(0.3))\n",
    "pixel_cnn.add(Dense(ytrain_ohe[0].shape[0], activation='softmax'))\n",
    "\n",
    "# Training\n",
    "pixel_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "pixel_cnn.fit(Xtrain, ytrain_ohe, epochs=30, batch_size=128, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(pixel_cnn, Xtrain, ytrain, Xtest, ytest, Xval, yval, 'pixel cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats et réponses:\n",
    "Vos résultats ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple\n",
    "\n",
    "| Ensemble | My CNN   |\n",
    "|----------|----------|\n",
    "| App      | 74.83%   |\n",
    "| Val      | 46.75%   |\n",
    "| Test     | 47.92%   |\n",
    "| Moyenne  | 56.50%   |\n",
    "\n",
    " \n",
    "Q1: Nous avons choisi l'algorithme d'arbre de décision parce que...\n",
    "\n",
    "Q2: Les taux de classification indiquent que le modèle...\n",
    "\n",
    "Q3: La performance avec le primitive..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b: Code CNN Pré-entraîné (FER)\n",
    "\n",
    "##### À faire:\n",
    "1. Récupérer une des architectures [CNN pré-entraînes disponibles dans Keras](https://keras.io/api/applications/) pour faire un \"transfert de connaissance\" (transfer learning). Faire un \"fine-tuning\" du modèle choisi sur FER.    \n",
    "2. Entraîner et optimiser les paramètres du réseau.\n",
    "3. Évaluer la pertinence d’utiliser \"data augmentation\" pour améliorer la généralisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_rgb, Xval_rgb, Xtest_rgb = convert_to_rgb(Xtrain, Xval, Xtest, 48, 48)\n",
    "Xtrain_stacked_grayscale, Xval_stacked_grayscale, Xtest_stacked_grayscale = convert_grayscale_to_3_channels(Xtrain, Xval, Xtest, 48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pretrained_resnet50 = ResNet50(include_top=False,\n",
    "                               input_shape=(48,48,3),\n",
    "                               pooling='avg',classes=len(labels),\n",
    "                               weights='imagenet')\n",
    "\n",
    "resnet50 = transfer_train(pretrained_resnet50, Xtrain_rgb, ytrain_ohe)\n",
    "resnet50.save(\"Models/resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_mobilenet = MobileNetV2(include_top=False,\n",
    "                               input_shape=(48,48,3),\n",
    "                               pooling='avg',classes=len(labels),\n",
    "                               weights='imagenet')\n",
    "\n",
    "mobilenet = transfer_train(pretrained_mobilenet, Xtrain_rgb, ytrain_ohe)\n",
    "mobilenet.save(\"Models/mobilenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vgg19 = VGG19(include_top=False,\n",
    "                               input_shape=(48,48,3),\n",
    "                               pooling='avg',classes=len(labels),\n",
    "                               weights='imagenet')\n",
    "\n",
    "vgg19 = transfer_train(pretrained_vgg19, Xtrain_rgb, ytrain_ohe)\n",
    "vgg19.save('Models/vgg19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_EfficientNetV2L= EfficientNetV2L(include_top=False,\n",
    "                               input_shape=(48,48,3),\n",
    "                               pooling='avg',classes=len(labels),\n",
    "                               weights='imagenet')\n",
    "\n",
    "efficientNetV2L = transfer_train(pretrained_vgg19, Xtrain_rgb, ytrain_ohe)\n",
    "efficientNetV2L.save('Models/efficientNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats et réponses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = keras.models.load_model(\"Models/resnet50\")\n",
    "mobilenet = keras.models.load_model(\"Models/mobilenet\")\n",
    "vgg19 = keras.models.load_model('Models/vgg19')\n",
    "efficientNetV2L = keras.models.load_model('Models/efficientNet')\n",
    "\n",
    "eval_model(resnet50, Xtrain_stacked_grayscale, ytrain, Xtest_stacked_grayscale, ytest, Xval_stacked_grayscale, yval, 'pixel ResNet50')\n",
    "eval_model(mobilenet, Xtrain_stacked_grayscale, ytrain, Xtest_stacked_grayscale, ytest, Xval_stacked_grayscale, yval, 'pixel MobileNet')\n",
    "eval_model(vgg19, Xtrain_stacked_grayscale, ytrain, Xtest_stacked_grayscale, ytest, Xval_stacked_grayscale, yval, 'pixel ResNet50')\n",
    "eval_model(efficientNetV2L, Xtrain_stacked_grayscale, ytrain, Xtest_stacked_grayscale, ytest, Xval_stacked_grayscale, yval, 'pixel ResNet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vos résultats ici\n",
    "\n",
    "##### Exemple:\n",
    "| Ensemble | My CNN   | Resnet50   | MobileNet | VGG 19 | EfficientNetV2L |\n",
    "|----------|----------|------------|-----------|--------|-----------------|\n",
    "| App      | 74.83%   |     80.32% |    47.29% | 62.84% |          65.58% |\n",
    "| Val      | 46.75%   |     43.69% |    30.29% | 37.16% |          39.45% |\n",
    "| Test     | 47.92%   |     45.33% |    29.73% | 39.12% |          39.98% |\n",
    "| Moyenne  | 56.50%   |     56.45% |    35.77% | 47.06% |          48.34% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c: Code CNN Pré-entraîné (FG-NET):\n",
    "\n",
    "##### À faire:\n",
    "1. Choisir le modèle \\ l’architecture qu’a donné de meilleurs résultats sur FER pour faire un “transfert de connaissance (transfer learning).\n",
    "2. Adapter ce modèle pour FG-NET (couche de sortie classification (7 unités avec softmax) -> régression (1 unité lineaire)).   \n",
    "3. Entraîner (\"fine-tuning\" du modèle choisi sur FG-NET) et optimiser les paramètres du réseau pour la régression.\n",
    "4. Évaluer la pertinence d’utiliser \"data augmentation\" pour améliorer la généralisation.\n",
    "5. Faire une analyse des résultats et présenter vos conclusions sur les réseaux de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"pixel\"\n",
    "# Create the model\n",
    "pixel_cnn = Sequential()\n",
    "\n",
    "pixel_cnn.add(Conv2D(16, (5, 5), padding='same', input_shape=Xtrain[0].shape, activation='relu'))\n",
    "pixel_cnn.add(AveragePooling2D((2, 2), strides=2))\n",
    "\n",
    "pixel_cnn.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "pixel_cnn.add(AveragePooling2D((2, 2), strides=2))\n",
    "\n",
    "pixel_cnn.add(Flatten()),\n",
    "pixel_cnn.add(Dense(120, activation='relu'))\n",
    "pixel_cnn.add(Dropout(0.3))\n",
    "pixel_cnn.add(Dense(84, activation='relu'))\n",
    "pixel_cnn.add(Dropout(0.3))\n",
    "pixel_cnn.add(Dense(42, activation='relu'))\n",
    "pixel_cnn.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Training\n",
    "pixel_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "pixel_cnn.fit(Xtrain, ytrain_ohe, epochs=30, batch_size=128, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats et réponses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vos résultats ici\n",
    "\n",
    "##### Exemple:\n",
    "| Ensemble | My CNN   | VGG19 CNN           |                               \n",
    "|----------|----------|---------------------|\n",
    "| App      | 99,67%   |     XX,XX%          |                   \n",
    "| Val      | 89,77%   |     XX,XX%          |                             \n",
    "| Test     | 77,99%   |     XX,XX%          |       \n",
    "\n",
    "\n",
    "Q1: Nous avons choisi l'algorithme d'arbre de décision parce que...\n",
    "\n",
    "Q2: Les taux de classification indiquent que le modèle...\n",
    "\n",
    "Q3: La performance avec le primitive..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie Final: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### À faire:\n",
    "1. Résumer et comparer les principaux résultats obtenus pour la classification (FER) et régression (FG-NET).\n",
    "2. Faire une analyse des résultats obtenus et présenter vos conclusions sur les différents modèles que vous avez entraînés (classification et régression).\n",
    "3. Comparer les résultats obtenus sur FER avec les résultats du laboratoire 1 (vecteur de pixels, vecteur de primitives). Avez-vous observé une amélioration? Commenter sur les temps d'apprentissage, complexité spatiale et temporelle, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats et réponses:\n",
    "Vos résultats ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithme            | MSE           |\n",
    "|-----------------------|---------------|\n",
    "| Regr lineaire         | XXX.XX        |\n",
    "| Regr Ridge            | XXX.XX        |\n",
    "| Regr Lasso            | XXX.XX        |\n",
    "| Regr ElasticNet       | XXX.XX        |\n",
    "| ...                   | XXX.XX        |\n",
    "| ...                   | XXX.XX        |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('GTI771-3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2cc76b7ba6e4a9b71994c9389777e7f76d395fe05acbae764e416f09af23599"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
